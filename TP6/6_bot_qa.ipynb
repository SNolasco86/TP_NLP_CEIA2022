{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## LSTM Bot QA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqO0PRcFsPTe"
      },
      "source": [
        "### Datos\n",
        "El objecto es utilizar datos disponibles de convai de conversaciones en ingleś. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n",
        "[LINK](http://convai.io/data/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown --quiet"
      ],
      "metadata": {
        "id": "bDFC0I3j9oFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM, SimpleRNN\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHNkUaPp6aYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09221da1-0cfa-4aef-8e06-fd24afe97b67"
      },
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import gdown\n",
        "if os.access('data_volunteers.json', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n",
        "    output = 'data_volunteers.json'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El dataset ya se encuentra descargado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZy1-wgG-Rp7"
      },
      "source": [
        "# dataset_file\n",
        "import json\n",
        "\n",
        "text_file = \"data_volunteers.json\"\n",
        "with open(text_file) as f:\n",
        "    data = json.load(f)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue5qd54S-eew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "750c513e-c7c6-4ef6-c4db-d805d5aaf1f9"
      },
      "source": [
        "# Observar los campos disponibles en cada linea del dataset\n",
        "data[0].keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHBRAXPl-3dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d23acf-53db-4228-fa13-b99119234215"
      },
      "source": [
        "chat_in = []\n",
        "chat_out = []\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "max_len = 30\n",
        "\n",
        "def clean_text(txt):\n",
        "    txt = txt.lower()    \n",
        "    txt.replace(\"\\'d\", \" had\")\n",
        "    txt.replace(\"\\'s\", \" is\")\n",
        "    txt.replace(\"\\'m\", \" am\")\n",
        "    txt.replace(\"don't\", \"do not\")\n",
        "    txt = re.sub(r'\\W+', ' ', txt)\n",
        "    \n",
        "    return txt\n",
        "\n",
        "for line in data:\n",
        "    for i in range(len(line['dialog'])-1):\n",
        "        chat_in = clean_text(line['dialog'][i]['text'])\n",
        "        chat_out = clean_text(line['dialog'][i+1]['text'])\n",
        "\n",
        "        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n",
        "            continue\n",
        "\n",
        "        input_sentence, output = chat_in, chat_out\n",
        "        \n",
        "        # output sentence (decoder_output) tiene <eos>\n",
        "        output_sentence = output + ' <eos>'\n",
        "        # output sentence input (decoder_input) tiene <sos>\n",
        "        output_sentence_input = '<sos> ' + output\n",
        "\n",
        "        input_sentences.append(input_sentence)\n",
        "        output_sentences.append(output_sentence)\n",
        "        output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows utilizadas: 6033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07L1qj8pC_l6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50501bda-3dc4-45d6-9a00-0daf7c6ae8ea"
      },
      "source": [
        "input_sentences[1], output_sentences[1], output_sentences_inputs[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "### 2 - Preprocesamiento\n",
        "Realizar el preprocesamiento necesario para obtener:\n",
        "- word2idx_inputs, max_input_len\n",
        "- word2idx_outputs, max_out_len, num_words_output\n",
        "- encoder_input_sequences, decoder_output_sequences, decoder_targets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el tamaño máximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 2000"
      ],
      "metadata": {
        "id": "L13wtT99yMt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### word2idx_inputs, max_input_len"
      ],
      "metadata": {
        "id": "zrjx_WAYpSyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizar las palabras con el Tokenizer de Keras\n",
        "# Definir una máxima cantidad de palabras a utilizar:\n",
        "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
        "# - Only the most common num_words-1 words will be kept.\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Sentencia de entrada más larga:\", max_input_len)"
      ],
      "metadata": {
        "id": "_h-STe-KDeTc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12992a55-e206-4f75-ccef-01e9893f3cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 1799\n",
            "Sentencia de entrada más larga: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### word2idx_outputs, max_out_len, num_words_output"
      ],
      "metadata": {
        "id": "szYhv4TKpWd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
        "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
        "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
        "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
        "\n",
        "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) \n",
        "# Se suma 1 para incluir el token de palabra desconocida\n",
        "\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Sentencia de salida más larga:\", max_out_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6UQd7jYpMoG",
        "outputId": "05a33506-b2a1-45ab-c159-e3e10c376276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 1806\n",
            "Sentencia de salida más larga: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### encoder_input_sequences, decoder_output_sequences, decoder_targets"
      ],
      "metadata": {
        "id": "fXoQ4kOipZqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc9S3z-hpbOH",
        "outputId": "be8771b9-212b-4a67-b993-0d119491445d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows del dataset: 6033\n",
            "encoder_input_sequences shape: (6033, 9)\n",
            "decoder_input_sequences shape: (6033, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
        "decoder_targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyAUbh89piQR",
        "outputId": "abe5f939-1490-4be0-cb44-1fabf04def10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6033, 10, 1807)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "### 3 - Preparar los embeddings\n",
        "Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar los embeddings desde un google drive (es la forma más rápida)\n",
        "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
        "# disponibles descargar de la página oficial como se explica en el siguiente bloque\n",
        "import os\n",
        "import gdown\n",
        "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1KY6avD5I1eI2dxQzMkR3WExwKwRq2g94&export=download'\n",
        "    output = 'gloveembedding.pkl'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoDX64Ulpjzv",
        "outputId": "cf28dcdc-2684-4120-da6f-5b9ad2c05c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los embeddings gloveembedding.pkl ya están descargados\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class GloveEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
        "    PKL_PATH = 'gloveembedding.pkl'\n",
        "    N_FEATURES = 50\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60"
      ],
      "metadata": {
        "id": "A8_RG5DUpqHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Por una cuestion de RAM se utilizarán los embeddings de Glove de dimension 50\n",
        "model_embeddings = GloveEmbeddings()\n",
        "\n",
        "# Crear la Embedding matrix de las secuencias\n",
        "# en inglés\n",
        "\n",
        "print('preparing embedding matrix...')\n",
        "embed_dim = model_embeddings.N_FEATURES\n",
        "words_not_found = []\n",
        "\n",
        "# word_index provieen del tokenizer\n",
        "\n",
        "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word2idx_inputs.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "        \n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        words_not_found.append(word)\n",
        "\n",
        "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyHnlYuhprE9",
        "outputId": "bf1f7069-6b9b-4815-c047-053117c50685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preparing embedding matrix...\n",
            "number of null word embeddings: 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 4 - Entrenar el modelo\n",
        "Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T1BnwDNqTcs",
        "outputId": "7fd0bf21-001a-4745-ce36-f1aba6c9f761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "\n",
        "n_units = 128\n",
        "\n",
        "# define training encoder\n",
        "encoder_inputs = Input(shape=(max_input_len))\n",
        "\n",
        "#encoder_embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)\n",
        "\n",
        "encoder_embedding_layer = Embedding(\n",
        "          input_dim=nb_words,  # definido en el Tokenizador\n",
        "          output_dim=embed_dim,  # dimensión de los embeddings utilizados\n",
        "          input_length=max_input_len, # máxima sentencia de entrada\n",
        "          weights=[embedding_matrix],  # matrix de embeddings\n",
        "          trainable=False)      # marcar como layer no entrenable\n",
        "\n",
        "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
        "\n",
        "encoder = LSTM(n_units, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# define training decoder\n",
        "decoder_inputs = Input(shape=(max_out_len))\n",
        "decoder_embedding_layer = Embedding(input_dim=num_words_output, output_dim=n_units, input_length=max_out_len)\n",
        "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
        "\n",
        "#Dropout para mejorar el entrenamiento \n",
        "dropout = Dropout(rate=0.8)\n",
        "decoder_outputs = dropout(decoder_outputs)\n",
        "\n",
        "# Dense\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGDz1VoGqYDC",
        "outputId": "ed42c19f-9bfa-4671-82a4-8c0a909b2746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 9)]          0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 9, 50)        89950       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 10, 128)      231296      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 128),        91648       ['embedding[0][0]']              \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 10, 128),    131584      ['embedding_1[0][0]',            \n",
            "                                 (None, 128),                     'lstm[0][1]',                   \n",
            "                                 (None, 128)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 10, 128)      0           ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10, 1807)     233103      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 777,581\n",
            "Trainable params: 687,631\n",
            "Non-trainable params: 89,950\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo solo encoder\n",
        "\n",
        "# define inference encoder\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "metadata": {
        "id": "Af3nfMMbqZHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define inference decoder\n",
        "decoder_state_input_h = Input(shape=(n_units,))\n",
        "decoder_state_input_c = Input(shape=(n_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# En cada predicción habrá una sola palabra de entrada al decoder,\n",
        "# que es la realimentación de la palabra anterior\n",
        "# por lo que hay que modificar el input shape de la layer de Embedding\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "#Dropout para mejorar el entrenamiento \n",
        "dropout = Dropout(rate=0.8)\n",
        "decoder_outputs = dropout(decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "#plot_model(decoder_model, to_file='decoder_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "ly-prhirqiGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Se limita el entrenamiento a 70 epochs para evitar \"overfitting\", se incluye dropout"
      ],
      "metadata": {
        "id": "e8Y57OLhAOta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets,\n",
        "    epochs=250, \n",
        "    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fnkz6PGYqjq_",
        "outputId": "d893eae1-0ccf-4b01-aab8-8340d5e239ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "151/151 [==============================] - 11s 30ms/step - loss: 3.2441 - accuracy: 0.5106 - val_loss: 2.2544 - val_accuracy: 0.6266\n",
            "Epoch 2/250\n",
            "151/151 [==============================] - 3s 19ms/step - loss: 2.2263 - accuracy: 0.5932 - val_loss: 2.1455 - val_accuracy: 0.6323\n",
            "Epoch 3/250\n",
            "151/151 [==============================] - 3s 18ms/step - loss: 2.1160 - accuracy: 0.6057 - val_loss: 2.0856 - val_accuracy: 0.6319\n",
            "Epoch 4/250\n",
            "151/151 [==============================] - 3s 17ms/step - loss: 2.0168 - accuracy: 0.6261 - val_loss: 2.0128 - val_accuracy: 0.6691\n",
            "Epoch 5/250\n",
            "151/151 [==============================] - 3s 17ms/step - loss: 1.9085 - accuracy: 0.6558 - val_loss: 1.9333 - val_accuracy: 0.6812\n",
            "Epoch 6/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.8187 - accuracy: 0.6759 - val_loss: 1.8779 - val_accuracy: 0.6928\n",
            "Epoch 7/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.7495 - accuracy: 0.6901 - val_loss: 1.8416 - val_accuracy: 0.6972\n",
            "Epoch 8/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.6935 - accuracy: 0.6990 - val_loss: 1.8123 - val_accuracy: 0.7009\n",
            "Epoch 9/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.6488 - accuracy: 0.7061 - val_loss: 1.7894 - val_accuracy: 0.7036\n",
            "Epoch 10/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.6161 - accuracy: 0.7123 - val_loss: 1.7710 - val_accuracy: 0.7058\n",
            "Epoch 11/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.5822 - accuracy: 0.7156 - val_loss: 1.7567 - val_accuracy: 0.7121\n",
            "Epoch 12/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.5560 - accuracy: 0.7192 - val_loss: 1.7449 - val_accuracy: 0.7129\n",
            "Epoch 13/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.5280 - accuracy: 0.7233 - val_loss: 1.7385 - val_accuracy: 0.7147\n",
            "Epoch 14/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.5085 - accuracy: 0.7243 - val_loss: 1.7311 - val_accuracy: 0.7153\n",
            "Epoch 15/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.4966 - accuracy: 0.7260 - val_loss: 1.7171 - val_accuracy: 0.7158\n",
            "Epoch 16/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.4727 - accuracy: 0.7290 - val_loss: 1.7193 - val_accuracy: 0.7176\n",
            "Epoch 17/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.4594 - accuracy: 0.7304 - val_loss: 1.7108 - val_accuracy: 0.7191\n",
            "Epoch 18/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.4429 - accuracy: 0.7313 - val_loss: 1.7080 - val_accuracy: 0.7191\n",
            "Epoch 19/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.4234 - accuracy: 0.7338 - val_loss: 1.7001 - val_accuracy: 0.7197\n",
            "Epoch 20/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.4142 - accuracy: 0.7357 - val_loss: 1.7034 - val_accuracy: 0.7215\n",
            "Epoch 21/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.4038 - accuracy: 0.7360 - val_loss: 1.7013 - val_accuracy: 0.7218\n",
            "Epoch 22/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.3889 - accuracy: 0.7372 - val_loss: 1.7060 - val_accuracy: 0.7238\n",
            "Epoch 23/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.3775 - accuracy: 0.7378 - val_loss: 1.7045 - val_accuracy: 0.7225\n",
            "Epoch 24/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.3710 - accuracy: 0.7399 - val_loss: 1.6974 - val_accuracy: 0.7253\n",
            "Epoch 25/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.3613 - accuracy: 0.7396 - val_loss: 1.6969 - val_accuracy: 0.7233\n",
            "Epoch 26/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.3542 - accuracy: 0.7400 - val_loss: 1.6997 - val_accuracy: 0.7234\n",
            "Epoch 27/250\n",
            "151/151 [==============================] - 2s 13ms/step - loss: 1.3374 - accuracy: 0.7422 - val_loss: 1.6997 - val_accuracy: 0.7251\n",
            "Epoch 28/250\n",
            "151/151 [==============================] - 2s 13ms/step - loss: 1.3341 - accuracy: 0.7439 - val_loss: 1.7059 - val_accuracy: 0.7272\n",
            "Epoch 29/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.3218 - accuracy: 0.7437 - val_loss: 1.7014 - val_accuracy: 0.7268\n",
            "Epoch 30/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.3114 - accuracy: 0.7459 - val_loss: 1.7049 - val_accuracy: 0.7263\n",
            "Epoch 31/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.3041 - accuracy: 0.7452 - val_loss: 1.7061 - val_accuracy: 0.7263\n",
            "Epoch 32/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 1.2996 - accuracy: 0.7463 - val_loss: 1.7140 - val_accuracy: 0.7272\n",
            "Epoch 33/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.2883 - accuracy: 0.7466 - val_loss: 1.7128 - val_accuracy: 0.7273\n",
            "Epoch 34/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.2839 - accuracy: 0.7477 - val_loss: 1.7165 - val_accuracy: 0.7273\n",
            "Epoch 35/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.2758 - accuracy: 0.7492 - val_loss: 1.7068 - val_accuracy: 0.7275\n",
            "Epoch 36/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 1.2699 - accuracy: 0.7501 - val_loss: 1.7147 - val_accuracy: 0.7277\n",
            "Epoch 37/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.2654 - accuracy: 0.7501 - val_loss: 1.7161 - val_accuracy: 0.7289\n",
            "Epoch 38/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 1.2598 - accuracy: 0.7487 - val_loss: 1.7135 - val_accuracy: 0.7287\n",
            "Epoch 39/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.2526 - accuracy: 0.7509 - val_loss: 1.7219 - val_accuracy: 0.7290\n",
            "Epoch 40/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.2497 - accuracy: 0.7520 - val_loss: 1.7231 - val_accuracy: 0.7296\n",
            "Epoch 41/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.2375 - accuracy: 0.7514 - val_loss: 1.7247 - val_accuracy: 0.7287\n",
            "Epoch 42/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.2317 - accuracy: 0.7532 - val_loss: 1.7346 - val_accuracy: 0.7300\n",
            "Epoch 43/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 1.2283 - accuracy: 0.7530 - val_loss: 1.7341 - val_accuracy: 0.7295\n",
            "Epoch 44/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 1.2237 - accuracy: 0.7541 - val_loss: 1.7255 - val_accuracy: 0.7317\n",
            "Epoch 45/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.2154 - accuracy: 0.7540 - val_loss: 1.7469 - val_accuracy: 0.7292\n",
            "Epoch 46/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.2090 - accuracy: 0.7531 - val_loss: 1.7445 - val_accuracy: 0.7306\n",
            "Epoch 47/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 1.2077 - accuracy: 0.7549 - val_loss: 1.7464 - val_accuracy: 0.7305\n",
            "Epoch 48/250\n",
            "151/151 [==============================] - 2s 13ms/step - loss: 1.2040 - accuracy: 0.7546 - val_loss: 1.7514 - val_accuracy: 0.7312\n",
            "Epoch 49/250\n",
            "151/151 [==============================] - 2s 15ms/step - loss: 1.1895 - accuracy: 0.7570 - val_loss: 1.7627 - val_accuracy: 0.7313\n",
            "Epoch 50/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.1922 - accuracy: 0.7574 - val_loss: 1.7647 - val_accuracy: 0.7331\n",
            "Epoch 51/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.1833 - accuracy: 0.7573 - val_loss: 1.7688 - val_accuracy: 0.7317\n",
            "Epoch 52/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 1.1817 - accuracy: 0.7566 - val_loss: 1.7636 - val_accuracy: 0.7325\n",
            "Epoch 53/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 1.1790 - accuracy: 0.7576 - val_loss: 1.7822 - val_accuracy: 0.7320\n",
            "Epoch 54/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.1728 - accuracy: 0.7576 - val_loss: 1.7797 - val_accuracy: 0.7332\n",
            "Epoch 55/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.1651 - accuracy: 0.7581 - val_loss: 1.7801 - val_accuracy: 0.7329\n",
            "Epoch 56/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.1647 - accuracy: 0.7579 - val_loss: 1.7798 - val_accuracy: 0.7333\n",
            "Epoch 57/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.1577 - accuracy: 0.7601 - val_loss: 1.7930 - val_accuracy: 0.7334\n",
            "Epoch 58/250\n",
            "151/151 [==============================] - 2s 13ms/step - loss: 1.1529 - accuracy: 0.7600 - val_loss: 1.7930 - val_accuracy: 0.7346\n",
            "Epoch 59/250\n",
            "151/151 [==============================] - 2s 13ms/step - loss: 1.1499 - accuracy: 0.7590 - val_loss: 1.7850 - val_accuracy: 0.7325\n",
            "Epoch 60/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.1486 - accuracy: 0.7609 - val_loss: 1.8066 - val_accuracy: 0.7318\n",
            "Epoch 61/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.1400 - accuracy: 0.7609 - val_loss: 1.8154 - val_accuracy: 0.7343\n",
            "Epoch 62/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.1369 - accuracy: 0.7622 - val_loss: 1.8109 - val_accuracy: 0.7339\n",
            "Epoch 63/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.1356 - accuracy: 0.7606 - val_loss: 1.8342 - val_accuracy: 0.7319\n",
            "Epoch 64/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.1279 - accuracy: 0.7622 - val_loss: 1.8199 - val_accuracy: 0.7326\n",
            "Epoch 65/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.1257 - accuracy: 0.7625 - val_loss: 1.8318 - val_accuracy: 0.7326\n",
            "Epoch 66/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.1272 - accuracy: 0.7634 - val_loss: 1.8210 - val_accuracy: 0.7337\n",
            "Epoch 67/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.1164 - accuracy: 0.7638 - val_loss: 1.8471 - val_accuracy: 0.7339\n",
            "Epoch 68/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.1133 - accuracy: 0.7648 - val_loss: 1.8434 - val_accuracy: 0.7331\n",
            "Epoch 69/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.1107 - accuracy: 0.7648 - val_loss: 1.8556 - val_accuracy: 0.7346\n",
            "Epoch 70/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.1096 - accuracy: 0.7636 - val_loss: 1.8546 - val_accuracy: 0.7341\n",
            "Epoch 71/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0953 - accuracy: 0.7660 - val_loss: 1.8581 - val_accuracy: 0.7340\n",
            "Epoch 72/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0986 - accuracy: 0.7648 - val_loss: 1.8671 - val_accuracy: 0.7355\n",
            "Epoch 73/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0998 - accuracy: 0.7652 - val_loss: 1.8647 - val_accuracy: 0.7341\n",
            "Epoch 74/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0909 - accuracy: 0.7655 - val_loss: 1.8781 - val_accuracy: 0.7345\n",
            "Epoch 75/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0900 - accuracy: 0.7652 - val_loss: 1.8875 - val_accuracy: 0.7341\n",
            "Epoch 76/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0849 - accuracy: 0.7686 - val_loss: 1.8860 - val_accuracy: 0.7355\n",
            "Epoch 77/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0844 - accuracy: 0.7672 - val_loss: 1.9018 - val_accuracy: 0.7354\n",
            "Epoch 78/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0776 - accuracy: 0.7668 - val_loss: 1.9086 - val_accuracy: 0.7350\n",
            "Epoch 79/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0733 - accuracy: 0.7666 - val_loss: 1.8950 - val_accuracy: 0.7350\n",
            "Epoch 80/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0709 - accuracy: 0.7687 - val_loss: 1.9166 - val_accuracy: 0.7348\n",
            "Epoch 81/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0668 - accuracy: 0.7693 - val_loss: 1.9184 - val_accuracy: 0.7354\n",
            "Epoch 82/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0659 - accuracy: 0.7691 - val_loss: 1.9107 - val_accuracy: 0.7354\n",
            "Epoch 83/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0584 - accuracy: 0.7708 - val_loss: 1.9307 - val_accuracy: 0.7346\n",
            "Epoch 84/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0607 - accuracy: 0.7701 - val_loss: 1.9270 - val_accuracy: 0.7333\n",
            "Epoch 85/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0538 - accuracy: 0.7714 - val_loss: 1.9232 - val_accuracy: 0.7349\n",
            "Epoch 86/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0597 - accuracy: 0.7706 - val_loss: 1.9379 - val_accuracy: 0.7342\n",
            "Epoch 87/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0473 - accuracy: 0.7716 - val_loss: 1.9424 - val_accuracy: 0.7360\n",
            "Epoch 88/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0461 - accuracy: 0.7717 - val_loss: 1.9722 - val_accuracy: 0.7330\n",
            "Epoch 89/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0450 - accuracy: 0.7722 - val_loss: 1.9665 - val_accuracy: 0.7357\n",
            "Epoch 90/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0392 - accuracy: 0.7727 - val_loss: 1.9613 - val_accuracy: 0.7350\n",
            "Epoch 91/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0412 - accuracy: 0.7732 - val_loss: 1.9797 - val_accuracy: 0.7356\n",
            "Epoch 92/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0340 - accuracy: 0.7723 - val_loss: 1.9702 - val_accuracy: 0.7344\n",
            "Epoch 93/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0360 - accuracy: 0.7735 - val_loss: 1.9684 - val_accuracy: 0.7352\n",
            "Epoch 94/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0314 - accuracy: 0.7735 - val_loss: 1.9862 - val_accuracy: 0.7355\n",
            "Epoch 95/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0258 - accuracy: 0.7737 - val_loss: 1.9782 - val_accuracy: 0.7342\n",
            "Epoch 96/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0253 - accuracy: 0.7737 - val_loss: 1.9993 - val_accuracy: 0.7354\n",
            "Epoch 97/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0231 - accuracy: 0.7745 - val_loss: 1.9986 - val_accuracy: 0.7352\n",
            "Epoch 98/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0189 - accuracy: 0.7753 - val_loss: 1.9848 - val_accuracy: 0.7345\n",
            "Epoch 99/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0198 - accuracy: 0.7742 - val_loss: 1.9928 - val_accuracy: 0.7339\n",
            "Epoch 100/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0170 - accuracy: 0.7768 - val_loss: 2.0167 - val_accuracy: 0.7348\n",
            "Epoch 101/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0111 - accuracy: 0.7757 - val_loss: 2.0227 - val_accuracy: 0.7341\n",
            "Epoch 102/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0076 - accuracy: 0.7771 - val_loss: 2.0140 - val_accuracy: 0.7342\n",
            "Epoch 103/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0105 - accuracy: 0.7774 - val_loss: 2.0162 - val_accuracy: 0.7354\n",
            "Epoch 104/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0101 - accuracy: 0.7770 - val_loss: 2.0373 - val_accuracy: 0.7345\n",
            "Epoch 105/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 1.0051 - accuracy: 0.7772 - val_loss: 2.0270 - val_accuracy: 0.7354\n",
            "Epoch 106/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 1.0021 - accuracy: 0.7782 - val_loss: 2.0330 - val_accuracy: 0.7348\n",
            "Epoch 107/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.9940 - accuracy: 0.7783 - val_loss: 2.0726 - val_accuracy: 0.7343\n",
            "Epoch 108/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9941 - accuracy: 0.7780 - val_loss: 2.0419 - val_accuracy: 0.7356\n",
            "Epoch 109/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9968 - accuracy: 0.7787 - val_loss: 2.0611 - val_accuracy: 0.7354\n",
            "Epoch 110/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.9956 - accuracy: 0.7767 - val_loss: 2.0561 - val_accuracy: 0.7357\n",
            "Epoch 111/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.9894 - accuracy: 0.7786 - val_loss: 2.0751 - val_accuracy: 0.7341\n",
            "Epoch 112/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.9885 - accuracy: 0.7798 - val_loss: 2.0608 - val_accuracy: 0.7354\n",
            "Epoch 113/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.9845 - accuracy: 0.7793 - val_loss: 2.0620 - val_accuracy: 0.7347\n",
            "Epoch 114/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9794 - accuracy: 0.7811 - val_loss: 2.0680 - val_accuracy: 0.7353\n",
            "Epoch 115/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.9821 - accuracy: 0.7801 - val_loss: 2.0707 - val_accuracy: 0.7360\n",
            "Epoch 116/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9787 - accuracy: 0.7814 - val_loss: 2.0738 - val_accuracy: 0.7361\n",
            "Epoch 117/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9744 - accuracy: 0.7822 - val_loss: 2.0972 - val_accuracy: 0.7362\n",
            "Epoch 118/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9753 - accuracy: 0.7805 - val_loss: 2.0706 - val_accuracy: 0.7348\n",
            "Epoch 119/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.9722 - accuracy: 0.7822 - val_loss: 2.0913 - val_accuracy: 0.7339\n",
            "Epoch 120/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9668 - accuracy: 0.7823 - val_loss: 2.0977 - val_accuracy: 0.7339\n",
            "Epoch 121/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9673 - accuracy: 0.7813 - val_loss: 2.1059 - val_accuracy: 0.7361\n",
            "Epoch 122/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9620 - accuracy: 0.7823 - val_loss: 2.1081 - val_accuracy: 0.7359\n",
            "Epoch 123/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9659 - accuracy: 0.7830 - val_loss: 2.1164 - val_accuracy: 0.7361\n",
            "Epoch 124/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9593 - accuracy: 0.7840 - val_loss: 2.1345 - val_accuracy: 0.7351\n",
            "Epoch 125/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9587 - accuracy: 0.7830 - val_loss: 2.1162 - val_accuracy: 0.7361\n",
            "Epoch 126/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9569 - accuracy: 0.7855 - val_loss: 2.1177 - val_accuracy: 0.7352\n",
            "Epoch 127/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9552 - accuracy: 0.7826 - val_loss: 2.1226 - val_accuracy: 0.7350\n",
            "Epoch 128/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9505 - accuracy: 0.7845 - val_loss: 2.1160 - val_accuracy: 0.7355\n",
            "Epoch 129/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9523 - accuracy: 0.7842 - val_loss: 2.1269 - val_accuracy: 0.7346\n",
            "Epoch 130/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9499 - accuracy: 0.7832 - val_loss: 2.1439 - val_accuracy: 0.7358\n",
            "Epoch 131/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9485 - accuracy: 0.7831 - val_loss: 2.1363 - val_accuracy: 0.7352\n",
            "Epoch 132/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 0.9488 - accuracy: 0.7851 - val_loss: 2.1416 - val_accuracy: 0.7345\n",
            "Epoch 133/250\n",
            "151/151 [==============================] - 2s 13ms/step - loss: 0.9450 - accuracy: 0.7848 - val_loss: 2.1827 - val_accuracy: 0.7355\n",
            "Epoch 134/250\n",
            "151/151 [==============================] - 2s 14ms/step - loss: 0.9404 - accuracy: 0.7849 - val_loss: 2.1513 - val_accuracy: 0.7345\n",
            "Epoch 135/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9423 - accuracy: 0.7847 - val_loss: 2.1446 - val_accuracy: 0.7360\n",
            "Epoch 136/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9335 - accuracy: 0.7879 - val_loss: 2.1633 - val_accuracy: 0.7353\n",
            "Epoch 137/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9364 - accuracy: 0.7871 - val_loss: 2.1864 - val_accuracy: 0.7342\n",
            "Epoch 138/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9350 - accuracy: 0.7869 - val_loss: 2.1592 - val_accuracy: 0.7346\n",
            "Epoch 139/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.9303 - accuracy: 0.7887 - val_loss: 2.1643 - val_accuracy: 0.7349\n",
            "Epoch 140/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9294 - accuracy: 0.7870 - val_loss: 2.1748 - val_accuracy: 0.7340\n",
            "Epoch 141/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9311 - accuracy: 0.7880 - val_loss: 2.1746 - val_accuracy: 0.7330\n",
            "Epoch 142/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9276 - accuracy: 0.7883 - val_loss: 2.2011 - val_accuracy: 0.7350\n",
            "Epoch 143/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9307 - accuracy: 0.7878 - val_loss: 2.1986 - val_accuracy: 0.7343\n",
            "Epoch 144/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9267 - accuracy: 0.7885 - val_loss: 2.1795 - val_accuracy: 0.7331\n",
            "Epoch 145/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 0.9192 - accuracy: 0.7897 - val_loss: 2.2032 - val_accuracy: 0.7355\n",
            "Epoch 146/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9196 - accuracy: 0.7895 - val_loss: 2.1995 - val_accuracy: 0.7347\n",
            "Epoch 147/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9202 - accuracy: 0.7885 - val_loss: 2.2141 - val_accuracy: 0.7339\n",
            "Epoch 148/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9183 - accuracy: 0.7885 - val_loss: 2.2223 - val_accuracy: 0.7350\n",
            "Epoch 149/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9096 - accuracy: 0.7904 - val_loss: 2.2096 - val_accuracy: 0.7331\n",
            "Epoch 150/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9080 - accuracy: 0.7916 - val_loss: 2.2377 - val_accuracy: 0.7328\n",
            "Epoch 151/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9134 - accuracy: 0.7887 - val_loss: 2.2162 - val_accuracy: 0.7354\n",
            "Epoch 152/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9084 - accuracy: 0.7912 - val_loss: 2.2067 - val_accuracy: 0.7334\n",
            "Epoch 153/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9038 - accuracy: 0.7913 - val_loss: 2.2229 - val_accuracy: 0.7333\n",
            "Epoch 154/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9031 - accuracy: 0.7918 - val_loss: 2.2393 - val_accuracy: 0.7344\n",
            "Epoch 155/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9079 - accuracy: 0.7918 - val_loss: 2.2144 - val_accuracy: 0.7335\n",
            "Epoch 156/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9047 - accuracy: 0.7904 - val_loss: 2.2315 - val_accuracy: 0.7347\n",
            "Epoch 157/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.9004 - accuracy: 0.7921 - val_loss: 2.2609 - val_accuracy: 0.7336\n",
            "Epoch 158/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.9023 - accuracy: 0.7928 - val_loss: 2.2581 - val_accuracy: 0.7337\n",
            "Epoch 159/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8972 - accuracy: 0.7939 - val_loss: 2.2450 - val_accuracy: 0.7339\n",
            "Epoch 160/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8973 - accuracy: 0.7937 - val_loss: 2.2626 - val_accuracy: 0.7346\n",
            "Epoch 161/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.8931 - accuracy: 0.7927 - val_loss: 2.2794 - val_accuracy: 0.7329\n",
            "Epoch 162/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8962 - accuracy: 0.7931 - val_loss: 2.2541 - val_accuracy: 0.7341\n",
            "Epoch 163/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8947 - accuracy: 0.7932 - val_loss: 2.2513 - val_accuracy: 0.7336\n",
            "Epoch 164/250\n",
            "151/151 [==============================] - 2s 14ms/step - loss: 0.8938 - accuracy: 0.7923 - val_loss: 2.2539 - val_accuracy: 0.7338\n",
            "Epoch 165/250\n",
            "151/151 [==============================] - 2s 13ms/step - loss: 0.8885 - accuracy: 0.7944 - val_loss: 2.2881 - val_accuracy: 0.7342\n",
            "Epoch 166/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8896 - accuracy: 0.7920 - val_loss: 2.2747 - val_accuracy: 0.7347\n",
            "Epoch 167/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8854 - accuracy: 0.7928 - val_loss: 2.2743 - val_accuracy: 0.7340\n",
            "Epoch 168/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8883 - accuracy: 0.7923 - val_loss: 2.2801 - val_accuracy: 0.7339\n",
            "Epoch 169/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8841 - accuracy: 0.7930 - val_loss: 2.2994 - val_accuracy: 0.7354\n",
            "Epoch 170/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8855 - accuracy: 0.7937 - val_loss: 2.2914 - val_accuracy: 0.7350\n",
            "Epoch 171/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8787 - accuracy: 0.7949 - val_loss: 2.3041 - val_accuracy: 0.7359\n",
            "Epoch 172/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.8754 - accuracy: 0.7962 - val_loss: 2.2888 - val_accuracy: 0.7340\n",
            "Epoch 173/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8716 - accuracy: 0.7963 - val_loss: 2.2584 - val_accuracy: 0.7341\n",
            "Epoch 174/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.8767 - accuracy: 0.7953 - val_loss: 2.2905 - val_accuracy: 0.7334\n",
            "Epoch 175/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.8738 - accuracy: 0.7944 - val_loss: 2.2975 - val_accuracy: 0.7331\n",
            "Epoch 176/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8708 - accuracy: 0.7964 - val_loss: 2.3077 - val_accuracy: 0.7331\n",
            "Epoch 177/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.8694 - accuracy: 0.7974 - val_loss: 2.3176 - val_accuracy: 0.7343\n",
            "Epoch 178/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8692 - accuracy: 0.7973 - val_loss: 2.3125 - val_accuracy: 0.7338\n",
            "Epoch 179/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8676 - accuracy: 0.7976 - val_loss: 2.3481 - val_accuracy: 0.7332\n",
            "Epoch 180/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8657 - accuracy: 0.7966 - val_loss: 2.3352 - val_accuracy: 0.7339\n",
            "Epoch 181/250\n",
            "151/151 [==============================] - 2s 10ms/step - loss: 0.8644 - accuracy: 0.7967 - val_loss: 2.3174 - val_accuracy: 0.7331\n",
            "Epoch 182/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8655 - accuracy: 0.7952 - val_loss: 2.3457 - val_accuracy: 0.7331\n",
            "Epoch 183/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8591 - accuracy: 0.7972 - val_loss: 2.3376 - val_accuracy: 0.7331\n",
            "Epoch 184/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8644 - accuracy: 0.7972 - val_loss: 2.3577 - val_accuracy: 0.7331\n",
            "Epoch 185/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8581 - accuracy: 0.7974 - val_loss: 2.3238 - val_accuracy: 0.7336\n",
            "Epoch 186/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8595 - accuracy: 0.7990 - val_loss: 2.3400 - val_accuracy: 0.7331\n",
            "Epoch 187/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8578 - accuracy: 0.7984 - val_loss: 2.3439 - val_accuracy: 0.7340\n",
            "Epoch 188/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8552 - accuracy: 0.7988 - val_loss: 2.3400 - val_accuracy: 0.7336\n",
            "Epoch 189/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8526 - accuracy: 0.7993 - val_loss: 2.3598 - val_accuracy: 0.7334\n",
            "Epoch 190/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8472 - accuracy: 0.7994 - val_loss: 2.3603 - val_accuracy: 0.7319\n",
            "Epoch 191/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8552 - accuracy: 0.7990 - val_loss: 2.3734 - val_accuracy: 0.7341\n",
            "Epoch 192/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8532 - accuracy: 0.7985 - val_loss: 2.3870 - val_accuracy: 0.7327\n",
            "Epoch 193/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8447 - accuracy: 0.7991 - val_loss: 2.3584 - val_accuracy: 0.7322\n",
            "Epoch 194/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8482 - accuracy: 0.8008 - val_loss: 2.3911 - val_accuracy: 0.7340\n",
            "Epoch 195/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8491 - accuracy: 0.7989 - val_loss: 2.3838 - val_accuracy: 0.7328\n",
            "Epoch 196/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8448 - accuracy: 0.8016 - val_loss: 2.3868 - val_accuracy: 0.7342\n",
            "Epoch 197/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8409 - accuracy: 0.8003 - val_loss: 2.3936 - val_accuracy: 0.7331\n",
            "Epoch 198/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8385 - accuracy: 0.8014 - val_loss: 2.3654 - val_accuracy: 0.7321\n",
            "Epoch 199/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8376 - accuracy: 0.8022 - val_loss: 2.4086 - val_accuracy: 0.7330\n",
            "Epoch 200/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8346 - accuracy: 0.8019 - val_loss: 2.3972 - val_accuracy: 0.7337\n",
            "Epoch 201/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 0.8350 - accuracy: 0.8031 - val_loss: 2.3965 - val_accuracy: 0.7324\n",
            "Epoch 202/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8391 - accuracy: 0.8015 - val_loss: 2.3808 - val_accuracy: 0.7313\n",
            "Epoch 203/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8395 - accuracy: 0.8012 - val_loss: 2.4018 - val_accuracy: 0.7337\n",
            "Epoch 204/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8336 - accuracy: 0.8019 - val_loss: 2.4205 - val_accuracy: 0.7323\n",
            "Epoch 205/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8342 - accuracy: 0.8021 - val_loss: 2.4211 - val_accuracy: 0.7321\n",
            "Epoch 206/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8360 - accuracy: 0.8027 - val_loss: 2.4254 - val_accuracy: 0.7338\n",
            "Epoch 207/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8311 - accuracy: 0.8034 - val_loss: 2.4153 - val_accuracy: 0.7343\n",
            "Epoch 208/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8271 - accuracy: 0.8029 - val_loss: 2.4215 - val_accuracy: 0.7337\n",
            "Epoch 209/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8272 - accuracy: 0.8038 - val_loss: 2.4312 - val_accuracy: 0.7340\n",
            "Epoch 210/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8257 - accuracy: 0.8046 - val_loss: 2.4186 - val_accuracy: 0.7335\n",
            "Epoch 211/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8279 - accuracy: 0.8043 - val_loss: 2.4214 - val_accuracy: 0.7332\n",
            "Epoch 212/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8246 - accuracy: 0.8035 - val_loss: 2.4310 - val_accuracy: 0.7341\n",
            "Epoch 213/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8214 - accuracy: 0.8045 - val_loss: 2.4372 - val_accuracy: 0.7348\n",
            "Epoch 214/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8266 - accuracy: 0.8048 - val_loss: 2.4408 - val_accuracy: 0.7338\n",
            "Epoch 215/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8195 - accuracy: 0.8036 - val_loss: 2.4743 - val_accuracy: 0.7327\n",
            "Epoch 216/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8210 - accuracy: 0.8042 - val_loss: 2.4473 - val_accuracy: 0.7331\n",
            "Epoch 217/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8193 - accuracy: 0.8033 - val_loss: 2.4596 - val_accuracy: 0.7331\n",
            "Epoch 218/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8211 - accuracy: 0.8042 - val_loss: 2.4661 - val_accuracy: 0.7350\n",
            "Epoch 219/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8151 - accuracy: 0.8052 - val_loss: 2.4547 - val_accuracy: 0.7327\n",
            "Epoch 220/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8125 - accuracy: 0.8051 - val_loss: 2.4369 - val_accuracy: 0.7321\n",
            "Epoch 221/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8147 - accuracy: 0.8053 - val_loss: 2.4708 - val_accuracy: 0.7324\n",
            "Epoch 222/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8131 - accuracy: 0.8065 - val_loss: 2.4867 - val_accuracy: 0.7326\n",
            "Epoch 223/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8094 - accuracy: 0.8055 - val_loss: 2.4807 - val_accuracy: 0.7331\n",
            "Epoch 224/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8071 - accuracy: 0.8064 - val_loss: 2.4555 - val_accuracy: 0.7322\n",
            "Epoch 225/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 0.8097 - accuracy: 0.8065 - val_loss: 2.4824 - val_accuracy: 0.7329\n",
            "Epoch 226/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8129 - accuracy: 0.8052 - val_loss: 2.4524 - val_accuracy: 0.7324\n",
            "Epoch 227/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8047 - accuracy: 0.8071 - val_loss: 2.4617 - val_accuracy: 0.7335\n",
            "Epoch 228/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8073 - accuracy: 0.8062 - val_loss: 2.4864 - val_accuracy: 0.7335\n",
            "Epoch 229/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8064 - accuracy: 0.8069 - val_loss: 2.4799 - val_accuracy: 0.7323\n",
            "Epoch 230/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8113 - accuracy: 0.8059 - val_loss: 2.4590 - val_accuracy: 0.7333\n",
            "Epoch 231/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8024 - accuracy: 0.8067 - val_loss: 2.4808 - val_accuracy: 0.7317\n",
            "Epoch 232/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7974 - accuracy: 0.8089 - val_loss: 2.4931 - val_accuracy: 0.7328\n",
            "Epoch 233/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8071 - accuracy: 0.8070 - val_loss: 2.5204 - val_accuracy: 0.7326\n",
            "Epoch 234/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.8009 - accuracy: 0.8084 - val_loss: 2.5198 - val_accuracy: 0.7323\n",
            "Epoch 235/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7991 - accuracy: 0.8083 - val_loss: 2.5169 - val_accuracy: 0.7321\n",
            "Epoch 236/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7981 - accuracy: 0.8082 - val_loss: 2.5244 - val_accuracy: 0.7340\n",
            "Epoch 237/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7937 - accuracy: 0.8088 - val_loss: 2.5205 - val_accuracy: 0.7334\n",
            "Epoch 238/250\n",
            "151/151 [==============================] - 2s 13ms/step - loss: 0.7974 - accuracy: 0.8068 - val_loss: 2.5278 - val_accuracy: 0.7328\n",
            "Epoch 239/250\n",
            "151/151 [==============================] - 2s 13ms/step - loss: 0.7956 - accuracy: 0.8088 - val_loss: 2.5089 - val_accuracy: 0.7335\n",
            "Epoch 240/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7953 - accuracy: 0.8083 - val_loss: 2.5185 - val_accuracy: 0.7329\n",
            "Epoch 241/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7899 - accuracy: 0.8108 - val_loss: 2.5453 - val_accuracy: 0.7332\n",
            "Epoch 242/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7914 - accuracy: 0.8097 - val_loss: 2.4894 - val_accuracy: 0.7319\n",
            "Epoch 243/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7923 - accuracy: 0.8093 - val_loss: 2.5056 - val_accuracy: 0.7330\n",
            "Epoch 244/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7915 - accuracy: 0.8105 - val_loss: 2.5366 - val_accuracy: 0.7330\n",
            "Epoch 245/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7878 - accuracy: 0.8095 - val_loss: 2.5629 - val_accuracy: 0.7329\n",
            "Epoch 246/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7889 - accuracy: 0.8096 - val_loss: 2.5381 - val_accuracy: 0.7335\n",
            "Epoch 247/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7848 - accuracy: 0.8105 - val_loss: 2.5577 - val_accuracy: 0.7320\n",
            "Epoch 248/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7846 - accuracy: 0.8097 - val_loss: 2.6086 - val_accuracy: 0.7335\n",
            "Epoch 249/250\n",
            "151/151 [==============================] - 2s 11ms/step - loss: 0.7846 - accuracy: 0.8100 - val_loss: 2.5626 - val_accuracy: 0.7323\n",
            "Epoch 250/250\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 0.7893 - accuracy: 0.8101 - val_loss: 2.5469 - val_accuracy: 0.7331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "I8H6lhxoqmZE",
        "outputId": "395caf2f-75b4-487a-f702-bee8f5ee32d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 - Inferencia\n",
        "Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."
      ],
      "metadata": {
        "id": "dR4tpvozqp0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Armar los conversores de índice a palabra:\n",
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "metadata": {
        "id": "XB3z4BP_qqbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(input_seq):\n",
        "    # Se transforma la sequencia de entrada a los estados \"h\" y \"c\" de la LSTM\n",
        "    # para enviar la primera vez al decoder\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "    # Se obtiene el índice que finaliza la inferencia\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "    \n",
        "    output_sentence = []\n",
        "    for _ in range(max_out_len):\n",
        "        # Predicción del próximo elemento\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        # Si es \"end of sentece <eos>\" se acaba\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        # Transformar idx a palabra\n",
        "        word = ''        \n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        # Actualizar los estados dada la última predicción\n",
        "        states_value = [h, c]\n",
        "\n",
        "        # Actualizar secuencia de entrada con la salida (re-alimentación)\n",
        "        target_seq[0, 0] = idx\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ],
      "metadata": {
        "id": "tz4rAewGqwOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test de bot"
      ],
      "metadata": {
        "id": "nHr8hBDUMT8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = np.random.choice(len(input_sentences))\n",
        "input_seq = encoder_input_sequences[i:i+1]\n",
        "translation = translate_sentence(input_seq)\n",
        "print('-')\n",
        "print('Input:', input_sentences[i])\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DdDIXN5qyWj",
        "outputId": "8d661d5b-75ef-4ecb-84d8-827d1bd56144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 336ms/step\n",
            "1/1 [==============================] - 0s 334ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "-\n",
            "Input: what do you do for a living \n",
            "Response: i am a student\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_test = \"Hello.\"\n",
        "print('Input:', input_test)\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "print('Input:', input_test)\n",
        "translation = translate_sentence(encoder_sequence_test)\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk7fd-EfqzPs",
        "outputId": "ed3a9578-f779-4293-d574-00d7cdb29971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Hello.\n",
            "Representacion en vector de tokens de ids [19]\n",
            "Padding del vector: [[ 0  0  0  0  0  0  0  0 19]]\n",
            "Input: Hello.\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Response: hello how are you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_test = \"How are you\"\n",
        "print('Input:', input_test)\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "print('Input:', input_test)\n",
        "translation = translate_sentence(encoder_sequence_test)\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gFfDIKV2Ocb",
        "outputId": "be3eb59d-b6ce-4e56-9579-684a89b16a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: How are you\n",
            "Representacion en vector de tokens de ids [10, 7, 2]\n",
            "Padding del vector: [[ 0  0  0  0  0  0 10  7  2]]\n",
            "Input: How are you\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Response: i am fine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listas de string para probar el chat"
      ],
      "metadata": {
        "id": "OUYUMJ9f-l8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = []\n",
        "text_list.append(\"Hi\")\n",
        "text_list.append(\"How are you\")\n",
        "text_list.append(\" What time is it?\")\n",
        "text_list.append(\"Could you please clarify?\")\n",
        "text_list.append(\"how much is it?\")\n",
        "text_list.append(\"Can you repeat it?\")\n",
        "text_list.append(\"Do you know the eiffel tower?\")\n",
        "text_list.append(\"Where is locate it?\")\n",
        "text_list.append(\"I would like to know Paris\")\n",
        "text_list.append(\"I want to go to Disney World too. Tell me where is it located\")\n",
        "text_list.append(\"What is your name?\")\n",
        "text_list.append(\"What is your favorite hobby?\")\n",
        "text_list.append(\"Is red a colour?\")\n",
        "text_list.append(\"what are you doing?\")\n",
        "text_list.append(\"Did you make your homework?\")\n",
        "text_list.append(\"see you later\")\n",
        "\n",
        "\n",
        "print(text_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAND0Va-61QA",
        "outputId": "692f0c81-a17c-4311-a7ac-ee33269ab821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi', 'How are you', ' What time is it?', 'Could you please clarify?', 'how much is it?', 'Can you repeat it?', 'Do you know the eiffel tower?', 'Where is locate it?', 'I would like to know Paris', 'I want to go to Disney World too. Tell me where is it located', 'What is your name?', 'What is your favorite hobby?', 'Is red a colour?', 'what are you doing?', 'Did you make your homework?', 'see you later']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text_list)):\n",
        "  \n",
        "  integer_seq_test = input_tokenizer.texts_to_sequences(text_list)[i]\n",
        "\n",
        "  encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "  \n",
        "\n",
        "  print('Input:', text_list[i])\n",
        "  translation = translate_sentence(encoder_sequence_test)\n",
        "  print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL4cZFaQ5-qh",
        "outputId": "f34acccb-f141-460d-af51-47802f7f3a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Hi\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Response: hello how are you\n",
            "Input: How are you\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Response: i am fine\n",
            "Input:  What time is it?\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Response: i like to go to the beach\n",
            "Input: Could you please clarify?\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Response: i love to go to the beach\n",
            "Input: how much is it?\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Response: i am not sure\n",
            "Input: Can you repeat it?\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Response: i am not sure what you mean\n",
            "Input: Do you know the eiffel tower?\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Response: i do not know what to say\n",
            "Input: Where is locate it?\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Response: i am a teacher i am a teacher\n",
            "Input: I would like to know Paris\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Response: i like to go to the beach\n",
            "Input: I want to go to Disney World too. Tell me where is it located\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Response: i like to read\n",
            "Input: What is your name?\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Response: i am not sure what you mean\n",
            "Input: What is your favorite hobby?\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Response: i like to play video games\n",
            "Input: Is red a colour?\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Response: what do you do for a living\n",
            "Input: what are you doing?\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Response: i am in the navy\n",
            "Input: Did you make your homework?\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Response: i am not sure what you mean\n",
            "Input: see you later\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Response: what do you do for a living\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6 - Conclusión\n",
        "\n",
        "Como conclusión es interesante las respuestas. El diccionario de preguntas tiene algunas muy elaboradas y cargadas de contexto, el algoritmo \"parsea\" algunas buscando la palabra más importante respondiendo finalmente erroneamente. Sin embargo hay otras por ejemplo cuando se le pregunta el hobby llega a contextualizar. Luego del dropout se vio una mejora en las respuestas"
      ],
      "metadata": {
        "id": "YFPpjpUu-ttE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Isn_ry-T_VMb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}